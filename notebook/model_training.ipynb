{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "99a79276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "46ea951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.5\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2afa3ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "print(type(xgb_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1e9dd442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synthetic data\n",
    "df = pd.read_csv(\"../data/sales_data.csv\", parse_dates=['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f7007",
   "metadata": {},
   "source": [
    "for each product_id, it looks at the last 7 days of sales (units_sold).\n",
    "It computes a rolling average → “on average, how many units were sold in the last week?”\n",
    "Helps smooth out fluctuations and capture short-term demand trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d19f9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['moving_avg_demand'] = df.groupby('product_id')['units_sold'].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dae0b0",
   "metadata": {},
   "source": [
    "Price elasticity measures how sensitive demand is to price changes.\n",
    "Formula: % change in demand ÷ % change in price.\n",
    "Example: If price goes up 10% and demand drops 20%, elasticity = -2 (demand is very sensitive).\n",
    "This feature helps the model understand if lowering the price will significantly increase sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f0120456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_elasticity'] = (df['units_sold'].pct_change() / df['historical_price'].pct_change()).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb58bf4",
   "metadata": {},
   "source": [
    "Similar to moving average but with a 30-day window.\n",
    "Captures long-term sales trends (seasonality, steady growth/decline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "32c75833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trend_factor'] = df.groupby('product_id')['units_sold'].transform(lambda x: x.rolling(30, min_periods=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe83ee3e",
   "metadata": {},
   "source": [
    "The model will use these features to predict the optimal price.\n",
    "Key features:\n",
    "Demand-related: units_sold, moving_avg_demand, trend_factor\n",
    "Competition-related: competitor_price\n",
    "Inventory-related: stock_level\n",
    "Behavioral signals: views (how many people looked at the product)\n",
    "Contextual factors: day_of_week, holiday_flag\n",
    "Elasticity: how demand reacts to price changes\n",
    "Target variable = historical_price → the model tries to learn pricing patterns from past data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c6ae5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['units_sold', 'competitor_price', 'stock_level', 'day_of_week', 'holiday_flag',\n",
    "            'views', 'moving_avg_demand', 'price_elasticity', 'trend_factor']\n",
    "target = 'historical_price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e80b1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df['moving_avg_demand'] = df.groupby('product_id')['units_sold'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
    "df['price_elasticity'] = (df['units_sold'].pct_change() / df['historical_price'].pct_change()).fillna(0)\n",
    "df['trend_factor'] = df.groupby('product_id')['units_sold'].transform(lambda x: x.rolling(30, min_periods=1).mean())\n",
    "\n",
    "features = ['units_sold', 'competitor_price', 'stock_level', 'day_of_week', 'holiday_flag',\n",
    "            'views', 'moving_avg_demand', 'price_elasticity', 'trend_factor']\n",
    "target = 'historical_price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "21d45d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e70514e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "682c27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"df\", exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "31d1880d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df/y_test.pkl']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X_test, \"df/X_test.pkl\")\n",
    "joblib.dump(y_test, \"df/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a3f172fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units_sold                0\n",
      "competitor_price          0\n",
      "stock_level               0\n",
      "day_of_week               0\n",
      "holiday_flag              0\n",
      "views                     0\n",
      "moving_avg_demand         0\n",
      "price_elasticity     116584\n",
      "trend_factor              0\n",
      "dtype: int64\n",
      "units_sold           0\n",
      "competitor_price     0\n",
      "stock_level          0\n",
      "day_of_week          0\n",
      "holiday_flag         0\n",
      "views                0\n",
      "moving_avg_demand    0\n",
      "price_elasticity     0\n",
      "trend_factor         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(np.isinf(X_train).sum())   # Count of infinite values\n",
    "print(np.isnan(X_train).sum())   # Count of NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ff1e17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set missing values:\n",
      " units_sold           0\n",
      "competitor_price     0\n",
      "stock_level          0\n",
      "day_of_week          0\n",
      "holiday_flag         0\n",
      "views                0\n",
      "moving_avg_demand    0\n",
      "price_elasticity     0\n",
      "trend_factor         0\n",
      "dtype: int64\n",
      "Test set missing values:\n",
      " units_sold           0\n",
      "competitor_price     0\n",
      "stock_level          0\n",
      "day_of_week          0\n",
      "holiday_flag         0\n",
      "views                0\n",
      "moving_avg_demand    0\n",
      "price_elasticity     0\n",
      "trend_factor         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace inf/-inf with NaN in both train and test sets\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill specific column 'price_elasticity' NaNs with 0\n",
    "X_train['price_elasticity'] = X_train['price_elasticity'].fillna(0)\n",
    "X_test['price_elasticity'] = X_test['price_elasticity'].fillna(0)\n",
    "\n",
    "# Fill any remaining NaNs in all columns with 0\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Optional: Verify\n",
    "print(\"Train set missing values:\\n\", X_train.isnull().sum())\n",
    "print(\"Test set missing values:\\n\", X_test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1468327",
   "metadata": {},
   "source": [
    "Key parameters:\n",
    "n_estimators=1000 → maximum number of boosting iterations (trees).\n",
    "learning_rate=0.05 → controls step size (smaller = slower but more accurate learning).\n",
    "max_depth=7 → limits how deep trees can grow (prevents overfitting).\n",
    "random_state=42 → ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3bd70d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20dbd8",
   "metadata": {},
   "source": [
    "Training on (X_train, y_train).\n",
    "Evaluating performance on a validation set (X_test, y_test).\n",
    "Early Stopping: If the model doesn’t improve for 50 rounds, training stops early to avoid overfitting.\n",
    "Log Evaluation: Prints evaluation metrics every 50 iterations so you can monitor progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "93702722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1091\n",
      "[LightGBM] [Info] Number of data points in the train set: 146400, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 275.740827\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\tvalid_0's l2: 194.668\n",
      "[100]\tvalid_0's l2: 98.0308\n",
      "[150]\tvalid_0's l2: 97.3593\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l2: 97.3554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/lgb_model.pkl']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "joblib.dump(lgb_model, '../models/lgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02743b54",
   "metadata": {},
   "source": [
    "XGBoost uses its own optimized data structure (DMatrix) for training.\n",
    "This makes training faster and memory-efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9a3dcf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f18e2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c983027",
   "metadata": {},
   "source": [
    "Similar to your LightGBM setup.\n",
    "reg:squarederror → standard regression objective.\n",
    "Using MAE as the metric since it’s interpretable in pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b2f27718",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",  # regression problem\n",
    "    \"learning_rate\": 0.05,            # step size\n",
    "    \"max_depth\": 7,                   # tree depth\n",
    "    \"eval_metric\": \"mae\"              # evaluation metric = Mean Absolute Error\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e20255f",
   "metadata": {},
   "source": [
    "Trains up to 1000 boosting rounds (trees).\n",
    "Uses early stopping: stops if no improvement for 10 rounds.\n",
    "save_best=True → keeps the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "050abafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-mae:103.39464\n",
      "[1]\tvalidation-mae:98.25597\n",
      "[2]\tvalidation-mae:93.37557\n",
      "[3]\tvalidation-mae:88.74124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\tvalidation-mae:84.33767\n",
      "[5]\tvalidation-mae:80.15652\n",
      "[6]\tvalidation-mae:76.18469\n",
      "[7]\tvalidation-mae:72.41474\n",
      "[8]\tvalidation-mae:68.83322\n",
      "[9]\tvalidation-mae:65.43345\n",
      "[10]\tvalidation-mae:62.20584\n",
      "[11]\tvalidation-mae:59.14166\n",
      "[12]\tvalidation-mae:56.23220\n",
      "[13]\tvalidation-mae:53.47088\n",
      "[14]\tvalidation-mae:50.84958\n",
      "[15]\tvalidation-mae:48.36273\n",
      "[16]\tvalidation-mae:46.00198\n",
      "[17]\tvalidation-mae:43.76359\n",
      "[18]\tvalidation-mae:41.63969\n",
      "[19]\tvalidation-mae:39.62636\n",
      "[20]\tvalidation-mae:37.71585\n",
      "[21]\tvalidation-mae:35.90444\n",
      "[22]\tvalidation-mae:34.18773\n",
      "[23]\tvalidation-mae:32.56018\n",
      "[24]\tvalidation-mae:31.01853\n",
      "[25]\tvalidation-mae:29.55871\n",
      "[26]\tvalidation-mae:28.17604\n",
      "[27]\tvalidation-mae:26.86707\n",
      "[28]\tvalidation-mae:25.62770\n",
      "[29]\tvalidation-mae:24.45620\n",
      "[30]\tvalidation-mae:23.34763\n",
      "[31]\tvalidation-mae:22.30014\n",
      "[32]\tvalidation-mae:21.31081\n",
      "[33]\tvalidation-mae:20.37618\n",
      "[34]\tvalidation-mae:19.49488\n",
      "[35]\tvalidation-mae:18.66526\n",
      "[36]\tvalidation-mae:17.88461\n",
      "[37]\tvalidation-mae:17.15046\n",
      "[38]\tvalidation-mae:16.46085\n",
      "[39]\tvalidation-mae:15.81509\n",
      "[40]\tvalidation-mae:15.21010\n",
      "[41]\tvalidation-mae:14.64328\n",
      "[42]\tvalidation-mae:14.11505\n",
      "[43]\tvalidation-mae:13.62362\n",
      "[44]\tvalidation-mae:13.16727\n",
      "[45]\tvalidation-mae:12.74374\n",
      "[46]\tvalidation-mae:12.35042\n",
      "[47]\tvalidation-mae:11.98710\n",
      "[48]\tvalidation-mae:11.65183\n",
      "[49]\tvalidation-mae:11.34189\n",
      "[50]\tvalidation-mae:11.05648\n",
      "[51]\tvalidation-mae:10.79468\n",
      "[52]\tvalidation-mae:10.55428\n",
      "[53]\tvalidation-mae:10.33459\n",
      "[54]\tvalidation-mae:10.13423\n",
      "[55]\tvalidation-mae:9.95174\n",
      "[56]\tvalidation-mae:9.78547\n",
      "[57]\tvalidation-mae:9.63388\n",
      "[58]\tvalidation-mae:9.49559\n",
      "[59]\tvalidation-mae:9.37063\n",
      "[60]\tvalidation-mae:9.25630\n",
      "[61]\tvalidation-mae:9.15254\n",
      "[62]\tvalidation-mae:9.05766\n",
      "[63]\tvalidation-mae:8.97194\n",
      "[64]\tvalidation-mae:8.89414\n",
      "[65]\tvalidation-mae:8.82433\n",
      "[66]\tvalidation-mae:8.76064\n",
      "[67]\tvalidation-mae:8.70249\n",
      "[68]\tvalidation-mae:8.64970\n",
      "[69]\tvalidation-mae:8.60171\n",
      "[70]\tvalidation-mae:8.55835\n",
      "[71]\tvalidation-mae:8.51928\n",
      "[72]\tvalidation-mae:8.48341\n",
      "[73]\tvalidation-mae:8.45074\n",
      "[74]\tvalidation-mae:8.42089\n",
      "[75]\tvalidation-mae:8.39404\n",
      "[76]\tvalidation-mae:8.36952\n",
      "[77]\tvalidation-mae:8.34718\n",
      "[78]\tvalidation-mae:8.32688\n",
      "[79]\tvalidation-mae:8.30849\n",
      "[80]\tvalidation-mae:8.29172\n",
      "[81]\tvalidation-mae:8.27607\n",
      "[82]\tvalidation-mae:8.26245\n",
      "[83]\tvalidation-mae:8.25002\n",
      "[84]\tvalidation-mae:8.23864\n",
      "[85]\tvalidation-mae:8.22820\n",
      "[86]\tvalidation-mae:8.21895\n",
      "[87]\tvalidation-mae:8.21040\n",
      "[88]\tvalidation-mae:8.20212\n",
      "[89]\tvalidation-mae:8.19470\n",
      "[90]\tvalidation-mae:8.18845\n",
      "[91]\tvalidation-mae:8.18252\n",
      "[92]\tvalidation-mae:8.17750\n",
      "[93]\tvalidation-mae:8.17257\n",
      "[94]\tvalidation-mae:8.16802\n",
      "[95]\tvalidation-mae:8.16413\n",
      "[96]\tvalidation-mae:8.16049\n",
      "[97]\tvalidation-mae:8.15747\n",
      "[98]\tvalidation-mae:8.15425\n",
      "[99]\tvalidation-mae:8.15147\n",
      "[100]\tvalidation-mae:8.14904\n",
      "[101]\tvalidation-mae:8.14689\n",
      "[102]\tvalidation-mae:8.14466\n",
      "[103]\tvalidation-mae:8.14271\n",
      "[104]\tvalidation-mae:8.14108\n",
      "[105]\tvalidation-mae:8.13969\n",
      "[106]\tvalidation-mae:8.13828\n",
      "[107]\tvalidation-mae:8.13677\n",
      "[108]\tvalidation-mae:8.13555\n",
      "[109]\tvalidation-mae:8.13445\n",
      "[110]\tvalidation-mae:8.13357\n",
      "[111]\tvalidation-mae:8.13276\n",
      "[112]\tvalidation-mae:8.13166\n",
      "[113]\tvalidation-mae:8.13117\n",
      "[114]\tvalidation-mae:8.13041\n",
      "[115]\tvalidation-mae:8.12988\n",
      "[116]\tvalidation-mae:8.12934\n",
      "[117]\tvalidation-mae:8.12897\n",
      "[118]\tvalidation-mae:8.12855\n",
      "[119]\tvalidation-mae:8.12814\n",
      "[120]\tvalidation-mae:8.12784\n",
      "[121]\tvalidation-mae:8.12775\n",
      "[122]\tvalidation-mae:8.12751\n",
      "[123]\tvalidation-mae:8.12724\n",
      "[124]\tvalidation-mae:8.12739\n",
      "[125]\tvalidation-mae:8.12714\n",
      "[126]\tvalidation-mae:8.12701\n",
      "[127]\tvalidation-mae:8.12677\n",
      "[128]\tvalidation-mae:8.12654\n",
      "[129]\tvalidation-mae:8.12619\n",
      "[130]\tvalidation-mae:8.12624\n",
      "[131]\tvalidation-mae:8.12610\n",
      "[132]\tvalidation-mae:8.12617\n",
      "[133]\tvalidation-mae:8.12599\n",
      "[134]\tvalidation-mae:8.12590\n",
      "[135]\tvalidation-mae:8.12579\n",
      "[136]\tvalidation-mae:8.12578\n",
      "[137]\tvalidation-mae:8.12580\n",
      "[138]\tvalidation-mae:8.12586\n",
      "[139]\tvalidation-mae:8.12599\n",
      "[140]\tvalidation-mae:8.12591\n",
      "[141]\tvalidation-mae:8.12575\n",
      "[142]\tvalidation-mae:8.12584\n",
      "[143]\tvalidation-mae:8.12588\n",
      "[144]\tvalidation-mae:8.12580\n",
      "[145]\tvalidation-mae:8.12590\n",
      "[146]\tvalidation-mae:8.12582\n",
      "[147]\tvalidation-mae:8.12592\n",
      "[148]\tvalidation-mae:8.12572\n",
      "[149]\tvalidation-mae:8.12576\n",
      "[150]\tvalidation-mae:8.12560\n",
      "[151]\tvalidation-mae:8.12594\n",
      "[152]\tvalidation-mae:8.12590\n",
      "[153]\tvalidation-mae:8.12582\n",
      "[154]\tvalidation-mae:8.12595\n",
      "[155]\tvalidation-mae:8.12598\n",
      "[156]\tvalidation-mae:8.12579\n",
      "[157]\tvalidation-mae:8.12586\n",
      "[158]\tvalidation-mae:8.12594\n",
      "[159]\tvalidation-mae:8.12599\n",
      "[160]\tvalidation-mae:8.12595\n"
     ]
    }
   ],
   "source": [
    "xgb_model= xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dtest, \"validation\")],\n",
    "    callbacks=[EarlyStopping(rounds=10, save_best=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "184d4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 150\n",
      "Best score: 8.125601074031142\n"
     ]
    }
   ],
   "source": [
    "print(\"Best iteration:\", xgb_model.best_iteration)\n",
    "print(\"Best score:\", xgb_model.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "40ed1a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model_dir = r\"C:\\Users\\KIIT\\Desktop\\dynamic_pricing_\\models\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # creates 'models' if it doesn't exist\n",
    "\n",
    "xgb_model.save_model(os.path.join(model_dir, \"xgb_model.json\"))\n",
    "\n",
    "print(\"XGBoost model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd3729",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "y_true: The actual prices (y_test).\n",
    "y_pred: The predicted prices from the model.\n",
    "model_name: A string (\"LightGBM\" or \"XGBoost\") just for labeling results.\n",
    "Metrics:\n",
    "\n",
    "MAE (Mean Absolute Error) → average absolute difference between predicted and true prices.\n",
    "→ “On average, how far off were we?”\n",
    "\n",
    "RMSE (Root Mean Squared Error) → square root of mean squared error.\n",
    "→ Similar to MAE but penalizes larger errors more (important in pricing where big mistakes hurt).\n",
    "\n",
    "Output: Prints a neat summary and returns (mae, rmse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7e155447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - MAE: 8.1385, RMSE: 9.8669\n",
      "XGBoost - MAE: 8.1256, RMSE: 9.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.125600814819336, np.float64(9.856024171205085))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))  # manual RMSE\n",
    "    print(f\"{model_name} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
    "    return mae, rmse\n",
    "\n",
    "# LightGBM predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "evaluate_model(y_test, y_pred_lgb, \"LightGBM\")\n",
    "\n",
    "# XGBoost predictions\n",
    "y_pred_xgb = xgb_model.predict(dtest)\n",
    "evaluate_model(y_test, y_pred_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96aec45",
   "metadata": {},
   "source": [
    "Creating two separate runs in the same experiment:\n",
    "One for LightGBM\n",
    "One for XGBoost\n",
    "\n",
    "Each run logs:\n",
    "Model artifact (lgb_model, xgb_model)\n",
    "Metrics (MAE, RMSE)\n",
    "\n",
    "In the MLflow UI (mlflow ui):\n",
    "there -two runs side by side under the dynamic_pricing experiment.\n",
    "\n",
    "filter/sort runs by MAE, RMSE to decide the winner.yeye"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvdp (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
